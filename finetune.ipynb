{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29c4938",
   "metadata": {},
   "source": [
    "# Imports & Load Previous Models\n",
    "\n",
    "We reuse:\n",
    "\n",
    "- the **PreCNN encoder**, which maps each CSI window to\n",
    "  an embedding vector $z_{\\text{pre}} \\in \\mathbb{R}^{128}$,\n",
    "- the **fusion model**, which takes $(z_{\\text{pre}}, z_{\\text{phys}})$\n",
    "  and outputs:\n",
    "\n",
    "  - presence logits / probabilities for the binary label\n",
    "    $y_{\\text{cls}} \\in \\{0,1\\}$ (empty vs non-empty),\n",
    "  - coordinates $\\hat{\\mathbf{p}} = (\\hat{x}, \\hat{y})$ for localization.\n",
    "\n",
    "In this notebook we fine-tune the fusion model in two phases while\n",
    "reusing the saved weights from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83a21c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:09:04.711266: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-15 19:09:04.717507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768504144.724681 2340938 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768504144.726885 2340938 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768504144.732486 2340938 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768504144.732492 2340938 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768504144.732493 2340938 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768504144.732494 2340938 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-15 19:09:04.734534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768504145.950815 2340938 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22181 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  encoder   = /home/tonyliao/Location_new_aoa_PDF/models/prec_encoder.h5\n",
      "  full_model= /home/tonyliao/Location_new_aoa_PDF/models/loc_full_model.h5\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 1 — Imports, Paths, Load Models\n",
    "# =========================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, losses, callbacks\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "\n",
    "MODEL_DIR = \"/home/tonyliao/Location_new_aoa_PDF/models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "ENC_SAVE_PATH   = f\"{MODEL_DIR}/prec_encoder.h5\"\n",
    "FULL_MODEL_PATH = f\"{MODEL_DIR}/loc_full_model.h5\"\n",
    "\n",
    "# Load without compile; we will re-compile below\n",
    "encoder = tf.keras.models.load_model(ENC_SAVE_PATH, compile=False)\n",
    "full_model = tf.keras.models.load_model(FULL_MODEL_PATH, compile=False)\n",
    "\n",
    "def euclid_mean(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)))\n",
    "\n",
    "# Helper: recursively find a submodel whose name contains keyword\n",
    "def find_submodel(root_model, keyword: str):\n",
    "    keyword = keyword.lower()\n",
    "    for layer in root_model.layers:\n",
    "        if isinstance(layer, tf.keras.Model) and keyword in layer.name.lower():\n",
    "            return layer\n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "            hit = find_submodel(layer, keyword)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    return None\n",
    "\n",
    "# Helper: set trainable recursively\n",
    "def set_trainable_recursive(root_model, trainable: bool, name_contains: str = None):\n",
    "    key = name_contains.lower() if name_contains else None\n",
    "    for layer in root_model.layers:\n",
    "        if (key is None) or (key in layer.name.lower()):\n",
    "            layer.trainable = trainable\n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "            set_trainable_recursive(layer, trainable, name_contains)\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\"  encoder   =\", ENC_SAVE_PATH)\n",
    "print(\"  full_model=\", FULL_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fc194c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded arrays:\n",
      "  Z_PRE : (166149, 128)\n",
      "  Z_PHYS: (166149, 5)\n",
      "  Y_cls : (166149,) int32\n",
      "  Y_loc : (166149, 2) float32\n",
      "Split:\n",
      "  Train: (132919, 128) (132919, 5) (132919,) (132919, 2)\n",
      "  Val  : (33230, 128) (33230, 5) (33230,) (33230, 2)\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 2 — Load Step3-5 Arrays + Train/Val Split\n",
    "# =========================================================\n",
    "Z_PRE_PATH   = \"/home/tonyliao/Location_new_aoa_PDF/Z_PRE.npy\"\n",
    "Z_PHYS_PATH  = \"/home/tonyliao/Location_new_aoa_PDF/Z_PHYS.npy\"\n",
    "YCLS_PATH    = \"/home/tonyliao/Location_new_aoa_PDF/Y_cls.npy\"\n",
    "YLOC_PATH    = \"/home/tonyliao/Location_new_aoa_PDF/coords.npy\"\n",
    "\n",
    "Z_PRE  = np.load(Z_PRE_PATH)\n",
    "Z_PHYS = np.load(Z_PHYS_PATH)\n",
    "Y_cls  = np.load(YCLS_PATH)\n",
    "Y_loc  = np.load(YLOC_PATH)\n",
    "\n",
    "print(\"Loaded arrays:\")\n",
    "print(\"  Z_PRE :\", Z_PRE.shape)\n",
    "print(\"  Z_PHYS:\", Z_PHYS.shape)\n",
    "print(\"  Y_cls :\", Y_cls.shape, Y_cls.dtype)\n",
    "print(\"  Y_loc :\", Y_loc.shape, Y_loc.dtype)\n",
    "\n",
    "N = len(Y_cls)\n",
    "rng = np.random.default_rng(42)\n",
    "idx = np.arange(N)\n",
    "rng.shuffle(idx)\n",
    "\n",
    "split = int(N * 0.8)\n",
    "train_idx, val_idx = idx[:split], idx[split:]\n",
    "\n",
    "Z_PRE_train,  Z_PRE_val  = Z_PRE[train_idx],  Z_PRE[val_idx]\n",
    "Z_PHYS_train, Z_PHYS_val = Z_PHYS[train_idx], Z_PHYS[val_idx]\n",
    "Y_cls_train,  Y_cls_val  = Y_cls[train_idx],  Y_cls[val_idx]\n",
    "Y_loc_train,  Y_loc_val  = Y_loc[train_idx],  Y_loc[val_idx]\n",
    "\n",
    "print(\"Split:\")\n",
    "print(\"  Train:\", Z_PRE_train.shape, Z_PHYS_train.shape, Y_cls_train.shape, Y_loc_train.shape)\n",
    "print(\"  Val  :\", Z_PRE_val.shape,  Z_PHYS_val.shape,  Y_cls_val.shape,  Y_loc_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c16f8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord_mean: [2.4951699 2.0143394]\n",
      "coord_std : [1.6937784 1.6303215]\n",
      "Saved coord_mean/std → /home/tonyliao/Location_new_aoa_PDF/models\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 3 — Coordinate Normalize + Save coord_mean/std\n",
    "# =========================================================\n",
    "coord_mean = Y_loc_train.mean(axis=0).astype(np.float32)\n",
    "coord_std  = (Y_loc_train.std(axis=0) + 1e-6).astype(np.float32)\n",
    "\n",
    "np.save(f\"{MODEL_DIR}/coord_mean.npy\", coord_mean)\n",
    "np.save(f\"{MODEL_DIR}/coord_std.npy\",  coord_std)\n",
    "\n",
    "Y_loc_train_n = ((Y_loc_train - coord_mean) / coord_std).astype(np.float32)\n",
    "Y_loc_val_n   = ((Y_loc_val   - coord_mean) / coord_std).astype(np.float32)\n",
    "\n",
    "print(\"coord_mean:\", coord_mean)\n",
    "print(\"coord_std :\", coord_std)\n",
    "print(\"Saved coord_mean/std →\", MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b5903d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: fallback freeze by name_contains='precnn'\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768504147.264410 2341054 service.cc:152] XLA service 0x7ff958002bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1768504147.264422 2341054 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2026-01-15 19:09:07.290184: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1768504147.455529 2341054 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1768504149.578553 2341054 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2026-01-15 19:09:14.517638: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2026-01-15 19:09:16.182663: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2026-01-15 19:09:16.185826: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2026-01-15 19:09:16.254047: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_201', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2026-01-15 19:09:17.154905: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2026-01-15 19:09:17.444868: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_208', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_coords_loss improved from inf to 0.43678, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 11s - 5ms/step - coords_euclid_mean: 0.7716 - coords_loss: 0.5109 - loss: 0.5168 - presence_accuracy: 0.9916 - presence_loss: 0.0294 - val_coords_euclid_mean: 0.6795 - val_coords_loss: 0.4368 - val_loss: 0.4368 - val_presence_accuracy: 1.0000 - val_presence_loss: 6.3131e-04\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 2: val_coords_loss improved from 0.43678 to 0.42372, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 3s - 2ms/step - coords_euclid_mean: 0.6739 - coords_loss: 0.4413 - loss: 0.4413 - presence_accuracy: 1.0000 - presence_loss: 2.6497e-04 - val_coords_euclid_mean: 0.6564 - val_coords_loss: 0.4237 - val_loss: 0.4237 - val_presence_accuracy: 1.0000 - val_presence_loss: 1.6154e-04\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 3: val_coords_loss did not improve from 0.42372\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6605 - coords_loss: 0.4338 - loss: 0.4339 - presence_accuracy: 1.0000 - presence_loss: 9.4205e-05 - val_coords_euclid_mean: 0.6501 - val_coords_loss: 0.4307 - val_loss: 0.4307 - val_presence_accuracy: 1.0000 - val_presence_loss: 4.6615e-05\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 4: val_coords_loss did not improve from 0.42372\n",
      "2077/2077 - 5s - 2ms/step - coords_euclid_mean: 0.6512 - coords_loss: 0.4276 - loss: 0.4276 - presence_accuracy: 1.0000 - presence_loss: 3.4595e-05 - val_coords_euclid_mean: 0.6558 - val_coords_loss: 0.4250 - val_loss: 0.4249 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.3569e-05\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 5: val_coords_loss improved from 0.42372 to 0.41730, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6480 - coords_loss: 0.4257 - loss: 0.4257 - presence_accuracy: 1.0000 - presence_loss: 1.5181e-05 - val_coords_euclid_mean: 0.6476 - val_coords_loss: 0.4173 - val_loss: 0.4173 - val_presence_accuracy: 1.0000 - val_presence_loss: 8.9946e-06\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 6: val_coords_loss did not improve from 0.41730\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6446 - coords_loss: 0.4243 - loss: 0.4243 - presence_accuracy: 1.0000 - presence_loss: 6.0900e-06 - val_coords_euclid_mean: 0.6515 - val_coords_loss: 0.4206 - val_loss: 0.4205 - val_presence_accuracy: 1.0000 - val_presence_loss: 4.0710e-06\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 7: val_coords_loss did not improve from 0.41730\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6433 - coords_loss: 0.4232 - loss: 0.4233 - presence_accuracy: 1.0000 - presence_loss: 2.1309e-06 - val_coords_euclid_mean: 0.6474 - val_coords_loss: 0.4223 - val_loss: 0.4222 - val_presence_accuracy: 1.0000 - val_presence_loss: 1.6819e-06\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 8: val_coords_loss did not improve from 0.41730\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6388 - coords_loss: 0.4203 - loss: 0.4203 - presence_accuracy: 1.0000 - presence_loss: 9.0751e-07 - val_coords_euclid_mean: 0.6545 - val_coords_loss: 0.4256 - val_loss: 0.4254 - val_presence_accuracy: 1.0000 - val_presence_loss: 6.8123e-07\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 9: val_coords_loss did not improve from 0.41730\n",
      "2077/2077 - 5s - 2ms/step - coords_euclid_mean: 0.6382 - coords_loss: 0.4199 - loss: 0.4199 - presence_accuracy: 1.0000 - presence_loss: 3.8932e-07 - val_coords_euclid_mean: 0.6478 - val_coords_loss: 0.4189 - val_loss: 0.4188 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.1111e-07\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 10: val_coords_loss improved from 0.41730 to 0.41215, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 5s - 2ms/step - coords_euclid_mean: 0.6353 - coords_loss: 0.4176 - loss: 0.4176 - presence_accuracy: 1.0000 - presence_loss: 1.3894e-07 - val_coords_euclid_mean: 0.6313 - val_coords_loss: 0.4121 - val_loss: 0.4120 - val_presence_accuracy: 1.0000 - val_presence_loss: 8.2594e-08\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 11: val_coords_loss did not improve from 0.41215\n",
      "2077/2077 - 5s - 3ms/step - coords_euclid_mean: 0.6340 - coords_loss: 0.4177 - loss: 0.4177 - presence_accuracy: 1.0000 - presence_loss: 8.0556e-08 - val_coords_euclid_mean: 0.6321 - val_coords_loss: 0.4160 - val_loss: 0.4159 - val_presence_accuracy: 1.0000 - val_presence_loss: 4.7633e-08\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 12: val_coords_loss did not improve from 0.41215\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6318 - coords_loss: 0.4149 - loss: 0.4149 - presence_accuracy: 1.0000 - presence_loss: 4.6908e-08 - val_coords_euclid_mean: 0.6375 - val_coords_loss: 0.4151 - val_loss: 0.4151 - val_presence_accuracy: 1.0000 - val_presence_loss: 3.6723e-08\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 13: val_coords_loss improved from 0.41215 to 0.41044, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 5s - 2ms/step - coords_euclid_mean: 0.6304 - coords_loss: 0.4150 - loss: 0.4150 - presence_accuracy: 1.0000 - presence_loss: 2.7527e-08 - val_coords_euclid_mean: 0.6284 - val_coords_loss: 0.4104 - val_loss: 0.4103 - val_presence_accuracy: 1.0000 - val_presence_loss: 9.4412e-09\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 14: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6311 - coords_loss: 0.4151 - loss: 0.4151 - presence_accuracy: 1.0000 - presence_loss: 1.2922e-08 - val_coords_euclid_mean: 0.6265 - val_coords_loss: 0.4106 - val_loss: 0.4105 - val_presence_accuracy: 1.0000 - val_presence_loss: 1.4500e-08\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 15: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6267 - coords_loss: 0.4116 - loss: 0.4116 - presence_accuracy: 1.0000 - presence_loss: 1.4686e-08 - val_coords_euclid_mean: 0.6353 - val_coords_loss: 0.4206 - val_loss: 0.4205 - val_presence_accuracy: 1.0000 - val_presence_loss: 1.1810e-08\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 3s - 1ms/step - coords_euclid_mean: 0.6261 - coords_loss: 0.4108 - loss: 0.4108 - presence_accuracy: 1.0000 - presence_loss: 2.9871e-08 - val_coords_euclid_mean: 0.6331 - val_coords_loss: 0.4214 - val_loss: 0.4213 - val_presence_accuracy: 1.0000 - val_presence_loss: 3.4850e-08\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 17: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6252 - coords_loss: 0.4117 - loss: 0.4117 - presence_accuracy: 1.0000 - presence_loss: 4.4819e-08 - val_coords_euclid_mean: 0.6348 - val_coords_loss: 0.4233 - val_loss: 0.4233 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.5494e-08\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 18: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6245 - coords_loss: 0.4107 - loss: 0.4107 - presence_accuracy: 1.0000 - presence_loss: 3.4295e-08 - val_coords_euclid_mean: 0.6283 - val_coords_loss: 0.4111 - val_loss: 0.4111 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.1637e-08\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 19: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6214 - coords_loss: 0.4079 - loss: 0.4079 - presence_accuracy: 1.0000 - presence_loss: 3.2145e-08 - val_coords_euclid_mean: 0.6272 - val_coords_loss: 0.4149 - val_loss: 0.4148 - val_presence_accuracy: 1.0000 - val_presence_loss: 5.7512e-08\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 20: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6208 - coords_loss: 0.4078 - loss: 0.4078 - presence_accuracy: 1.0000 - presence_loss: 3.7231e-08 - val_coords_euclid_mean: 0.6088 - val_coords_loss: 0.4105 - val_loss: 0.4104 - val_presence_accuracy: 1.0000 - val_presence_loss: 1.3698e-08\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 21: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 3s - 2ms/step - coords_euclid_mean: 0.6208 - coords_loss: 0.4077 - loss: 0.4077 - presence_accuracy: 1.0000 - presence_loss: 2.3412e-08 - val_coords_euclid_mean: 0.6353 - val_coords_loss: 0.4217 - val_loss: 0.4217 - val_presence_accuracy: 1.0000 - val_presence_loss: 5.3730e-09\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 22: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.6169 - coords_loss: 0.4047 - loss: 0.4047 - presence_accuracy: 1.0000 - presence_loss: 1.7811e-08 - val_coords_euclid_mean: 0.6327 - val_coords_loss: 0.4180 - val_loss: 0.4179 - val_presence_accuracy: 1.0000 - val_presence_loss: 7.9306e-09\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 23: val_coords_loss did not improve from 0.41044\n",
      "2077/2077 - 5s - 3ms/step - coords_euclid_mean: 0.6166 - coords_loss: 0.4045 - loss: 0.4045 - presence_accuracy: 1.0000 - presence_loss: 1.4738e-08 - val_coords_euclid_mean: 0.6193 - val_coords_loss: 0.4124 - val_loss: 0.4123 - val_presence_accuracy: 1.0000 - val_presence_loss: 3.4781e-09\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "✔ Phase 1 done.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 4 — Phase 1: Freeze PreCNN + Compile + Train\n",
    "# =========================================================\n",
    "# Freeze encoder copy (optional)\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Freeze the PreCNN inside full_model (robust)\n",
    "precnn = find_submodel(full_model, \"precnn\") or find_submodel(full_model, \"PreCNN\")\n",
    "if precnn is not None:\n",
    "    set_trainable_recursive(precnn, False)\n",
    "    print(\"Phase 1: froze submodel:\", precnn.name)\n",
    "else:\n",
    "    # fallback: freeze layers whose name contains 'precnn'\n",
    "    set_trainable_recursive(full_model, False, name_contains=\"precnn\")\n",
    "    print(\"Phase 1: fallback freeze by name_contains='precnn'\")\n",
    "\n",
    "LR_PHASE1 = 1e-3\n",
    "full_model.compile(\n",
    "    optimizer=optimizers.Adam(LR_PHASE1),\n",
    "    loss={\n",
    "        \"presence\": losses.SparseCategoricalCrossentropy(),\n",
    "        \"coords\":   losses.MeanSquaredError(),\n",
    "    },\n",
    "    loss_weights={\"presence\": 0.2, \"coords\": 1.0},\n",
    "    metrics={\"presence\": [\"accuracy\"], \"coords\": [euclid_mean]},\n",
    ")\n",
    "\n",
    "ckpt_phase1 = callbacks.ModelCheckpoint(\n",
    "    f\"{MODEL_DIR}/fine_phase1.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_coords_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=1,\n",
    ")\n",
    "es_phase1 = callbacks.EarlyStopping(\n",
    "    monitor=\"val_coords_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history_phase1 = full_model.fit(\n",
    "    x=[Z_PRE_train, Z_PHYS_train],\n",
    "    y={\"presence\": Y_cls_train, \"coords\": Y_loc_train_n},\n",
    "    validation_data=([Z_PRE_val, Z_PHYS_val], {\"presence\": Y_cls_val, \"coords\": Y_loc_val_n}),\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    callbacks=[ckpt_phase1, es_phase1],\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"✔ Phase 1 done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923abb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2: fallback unfreeze conv/bn layers in full_model\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 1: val_coords_euclid_mean improved from inf to 0.56499, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 8s - 4ms/step - coords_euclid_mean: 0.5711 - coords_loss: 0.1208 - loss: 0.1208 - presence_accuracy: 1.0000 - presence_loss: 7.3377e-09 - val_coords_euclid_mean: 0.5650 - val_coords_loss: 0.1205 - val_loss: 0.1205 - val_presence_accuracy: 1.0000 - val_presence_loss: 4.2698e-09\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 2: val_coords_euclid_mean improved from 0.56499 to 0.55502, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5530 - coords_loss: 0.1178 - loss: 0.1178 - presence_accuracy: 1.0000 - presence_loss: 5.1694e-09 - val_coords_euclid_mean: 0.5550 - val_coords_loss: 0.1189 - val_loss: 0.1189 - val_presence_accuracy: 1.0000 - val_presence_loss: 3.5784e-09\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 3: val_coords_euclid_mean improved from 0.55502 to 0.55259, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5472 - coords_loss: 0.1168 - loss: 0.1168 - presence_accuracy: 1.0000 - presence_loss: 3.9830e-09 - val_coords_euclid_mean: 0.5526 - val_coords_loss: 0.1187 - val_loss: 0.1187 - val_presence_accuracy: 1.0000 - val_presence_loss: 3.2202e-09\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 4: val_coords_euclid_mean improved from 0.55259 to 0.54989, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 5s - 2ms/step - coords_euclid_mean: 0.5449 - coords_loss: 0.1164 - loss: 0.1164 - presence_accuracy: 1.0000 - presence_loss: 3.9892e-09 - val_coords_euclid_mean: 0.5499 - val_coords_loss: 0.1183 - val_loss: 0.1183 - val_presence_accuracy: 1.0000 - val_presence_loss: 3.0232e-09\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 5: val_coords_euclid_mean did not improve from 0.54989\n",
      "2077/2077 - 5s - 3ms/step - coords_euclid_mean: 0.5421 - coords_loss: 0.1157 - loss: 0.1157 - presence_accuracy: 1.0000 - presence_loss: 3.9432e-09 - val_coords_euclid_mean: 0.5517 - val_coords_loss: 0.1182 - val_loss: 0.1182 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.7367e-09\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 6: val_coords_euclid_mean improved from 0.54989 to 0.54844, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 6s - 3ms/step - coords_euclid_mean: 0.5410 - coords_loss: 0.1156 - loss: 0.1156 - presence_accuracy: 1.0000 - presence_loss: 3.9541e-09 - val_coords_euclid_mean: 0.5484 - val_coords_loss: 0.1179 - val_loss: 0.1178 - val_presence_accuracy: 1.0000 - val_presence_loss: 3.1701e-09\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 7: val_coords_euclid_mean improved from 0.54844 to 0.54773, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5392 - coords_loss: 0.1151 - loss: 0.1151 - presence_accuracy: 1.0000 - presence_loss: 3.9943e-09 - val_coords_euclid_mean: 0.5477 - val_coords_loss: 0.1178 - val_loss: 0.1178 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.9158e-09\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 8: val_coords_euclid_mean did not improve from 0.54773\n",
      "2077/2077 - 5s - 3ms/step - coords_euclid_mean: 0.5376 - coords_loss: 0.1148 - loss: 0.1148 - presence_accuracy: 1.0000 - presence_loss: 3.8273e-09 - val_coords_euclid_mean: 0.5481 - val_coords_loss: 0.1180 - val_loss: 0.1179 - val_presence_accuracy: 1.0000 - val_presence_loss: 3.0447e-09\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 9: val_coords_euclid_mean improved from 0.54773 to 0.54750, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 5s - 2ms/step - coords_euclid_mean: 0.5371 - coords_loss: 0.1147 - loss: 0.1147 - presence_accuracy: 1.0000 - presence_loss: 3.4643e-09 - val_coords_euclid_mean: 0.5475 - val_coords_loss: 0.1176 - val_loss: 0.1176 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.8764e-09\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 10: val_coords_euclid_mean improved from 0.54750 to 0.54483, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5361 - coords_loss: 0.1144 - loss: 0.1144 - presence_accuracy: 1.0000 - presence_loss: 3.9783e-09 - val_coords_euclid_mean: 0.5448 - val_coords_loss: 0.1175 - val_loss: 0.1175 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.6829e-09\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 11: val_coords_euclid_mean did not improve from 0.54483\n",
      "2077/2077 - 5s - 3ms/step - coords_euclid_mean: 0.5349 - coords_loss: 0.1142 - loss: 0.1142 - presence_accuracy: 1.0000 - presence_loss: 3.5423e-09 - val_coords_euclid_mean: 0.5454 - val_coords_loss: 0.1175 - val_loss: 0.1175 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.5826e-09\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 12: val_coords_euclid_mean did not improve from 0.54483\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5338 - coords_loss: 0.1140 - loss: 0.1140 - presence_accuracy: 1.0000 - presence_loss: 3.9251e-09 - val_coords_euclid_mean: 0.5476 - val_coords_loss: 0.1174 - val_loss: 0.1174 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.7617e-09\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 13: val_coords_euclid_mean did not improve from 0.54483\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5326 - coords_loss: 0.1136 - loss: 0.1136 - presence_accuracy: 1.0000 - presence_loss: 3.3998e-09 - val_coords_euclid_mean: 0.5462 - val_coords_loss: 0.1175 - val_loss: 0.1175 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.1492e-09\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 14: val_coords_euclid_mean did not improve from 0.54483\n",
      "2077/2077 - 5s - 3ms/step - coords_euclid_mean: 0.5320 - coords_loss: 0.1135 - loss: 0.1135 - presence_accuracy: 1.0000 - presence_loss: 2.8860e-09 - val_coords_euclid_mean: 0.5457 - val_coords_loss: 0.1172 - val_loss: 0.1172 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.2029e-09\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 15: val_coords_euclid_mean improved from 0.54483 to 0.54456, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 5s - 2ms/step - coords_euclid_mean: 0.5312 - coords_loss: 0.1133 - loss: 0.1133 - presence_accuracy: 1.0000 - presence_loss: 2.9753e-09 - val_coords_euclid_mean: 0.5446 - val_coords_loss: 0.1174 - val_loss: 0.1173 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.2173e-09\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 16: val_coords_euclid_mean improved from 0.54456 to 0.54286, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5313 - coords_loss: 0.1133 - loss: 0.1133 - presence_accuracy: 1.0000 - presence_loss: 3.0913e-09 - val_coords_euclid_mean: 0.5429 - val_coords_loss: 0.1172 - val_loss: 0.1172 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.1277e-09\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 17: val_coords_euclid_mean did not improve from 0.54286\n",
      "2077/2077 - 5s - 2ms/step - coords_euclid_mean: 0.5303 - coords_loss: 0.1131 - loss: 0.1131 - presence_accuracy: 1.0000 - presence_loss: 2.9920e-09 - val_coords_euclid_mean: 0.5449 - val_coords_loss: 0.1179 - val_loss: 0.1179 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.1564e-09\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 18: val_coords_euclid_mean improved from 0.54286 to 0.54252, saving model to /home/tonyliao/Location_new_aoa_PDF/models/fine_phase2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5296 - coords_loss: 0.1129 - loss: 0.1129 - presence_accuracy: 1.0000 - presence_loss: 2.9981e-09 - val_coords_euclid_mean: 0.5425 - val_coords_loss: 0.1174 - val_loss: 0.1174 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.3641e-09\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 19: val_coords_euclid_mean did not improve from 0.54252\n",
      "2077/2077 - 4s - 2ms/step - coords_euclid_mean: 0.5284 - coords_loss: 0.1127 - loss: 0.1127 - presence_accuracy: 1.0000 - presence_loss: 3.2310e-09 - val_coords_euclid_mean: 0.5449 - val_coords_loss: 0.1176 - val_loss: 0.1175 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.3856e-09\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 20: val_coords_euclid_mean did not improve from 0.54252\n",
      "2077/2077 - 5s - 3ms/step - coords_euclid_mean: 0.5284 - coords_loss: 0.1127 - loss: 0.1127 - presence_accuracy: 1.0000 - presence_loss: 3.4045e-09 - val_coords_euclid_mean: 0.5464 - val_coords_loss: 0.1173 - val_loss: 0.1173 - val_presence_accuracy: 1.0000 - val_presence_loss: 2.2997e-09\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "✔ Phase 2 done.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 5 — Phase 2: Unfreeze Top PreCNN Blocks + Compile + Train\n",
    "# =========================================================\n",
    "def unfreeze_top_blocks(precnn_model: tf.keras.Model, keep_frozen_ratio: float = 0.70):\n",
    "    \"\"\"\n",
    "    Unfreeze only the last ~30% layers of the PreCNN submodel.\n",
    "    This is more robust than matching conv1d layer names.\n",
    "    \"\"\"\n",
    "    layers = precnn_model.layers\n",
    "    cut = int(len(layers) * keep_frozen_ratio)\n",
    "    for i, layer in enumerate(layers):\n",
    "        layer.trainable = (i >= cut)\n",
    "\n",
    "precnn = find_submodel(full_model, \"precnn\") or find_submodel(full_model, \"PreCNN\")\n",
    "if precnn is not None:\n",
    "    unfreeze_top_blocks(precnn, keep_frozen_ratio=0.70)\n",
    "    print(\"Phase 2: unfroze top blocks in:\", precnn.name)\n",
    "else:\n",
    "    # fallback: unfreeze conv/bn-ish layers by name if no submodel found\n",
    "    for layer in full_model.layers:\n",
    "        name = layer.name.lower()\n",
    "        if (\"conv\" in name) or (\"batch\" in name) or (\"bn\" in name):\n",
    "            layer.trainable = True\n",
    "    print(\"Phase 2: fallback unfreeze conv/bn layers in full_model\")\n",
    "\n",
    "LR_PHASE2 = 1e-4\n",
    "full_model.compile(\n",
    "    optimizer=optimizers.Adam(LR_PHASE2),\n",
    "    loss={\n",
    "        \"presence\": losses.SparseCategoricalCrossentropy(),\n",
    "        \"coords\":   losses.Huber(delta=0.5),\n",
    "    },\n",
    "    loss_weights={\"presence\": 0.2, \"coords\": 1.0},\n",
    "    metrics={\"presence\": [\"accuracy\"], \"coords\": [euclid_mean]},\n",
    ")\n",
    "\n",
    "ckpt_phase2 = callbacks.ModelCheckpoint(\n",
    "    f\"{MODEL_DIR}/fine_phase2.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_coords_euclid_mean\",\n",
    "    mode=\"min\",\n",
    "    verbose=1,\n",
    ")\n",
    "es_phase2 = callbacks.EarlyStopping(\n",
    "    monitor=\"val_coords_euclid_mean\",\n",
    "    mode=\"min\",\n",
    "    patience=12,\n",
    "    min_delta=1e-4,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history_phase2 = full_model.fit(\n",
    "    x=[Z_PRE_train, Z_PHYS_train],\n",
    "    y={\"presence\": Y_cls_train, \"coords\": Y_loc_train_n},\n",
    "    validation_data=([Z_PRE_val, Z_PHYS_val], {\"presence\": Y_cls_val, \"coords\": Y_loc_val_n}),\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    callbacks=[ckpt_phase2, es_phase2],\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"✔ Phase 2 done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f1a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved → /home/tonyliao/Location_new_aoa_PDF/models/final_finetuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 19:12:27.983603: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-01-15 19:12:28.048953: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_168', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-01-15 19:12:28.195355: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_168', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved coord_bias → /home/tonyliao/Location_new_aoa_PDF/models/coord_bias.npy\n",
      "coord_bias: [0.00610671 1.6157156 ]\n",
      "bias computed on samples: 33230 / 33230\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 6 — Save Final Model + Compute coord_bias.npy\n",
    "# =========================================================\n",
    "FINAL_SAVE = f\"{MODEL_DIR}/final_finetuned_model.h5\"\n",
    "full_model.save(FINAL_SAVE)\n",
    "print(\"Final model saved →\", FINAL_SAVE)\n",
    "\n",
    "# ---- compute coord_bias (Eq.8-style systematic offset correction) ----\n",
    "pred = full_model.predict([Z_PRE_val, Z_PHYS_val], verbose=0)\n",
    "\n",
    "def extract_coords_pred(pred_out):\n",
    "    # pred_out can be list/tuple or dict\n",
    "    if isinstance(pred_out, dict):\n",
    "        return pred_out[\"coords\"]\n",
    "    if isinstance(pred_out, (list, tuple)):\n",
    "        # pick the (N,2) array\n",
    "        for arr in pred_out:\n",
    "            if isinstance(arr, np.ndarray) and arr.ndim == 2 and arr.shape[1] == 2:\n",
    "                return arr\n",
    "    raise ValueError(\"Cannot find coords output in model.predict() result\")\n",
    "\n",
    "pred_loc_n = extract_coords_pred(pred).astype(np.float32)          # normalized coords\n",
    "pred_loc   = pred_loc_n * coord_std + coord_mean                   # real coords\n",
    "\n",
    "# Exclude \"empty\" samples if your Y_cls uses 0 as empty (common)\n",
    "EMPTY_CLASS_ID = 0\n",
    "mask = (Y_cls_val != EMPTY_CLASS_ID)\n",
    "if mask.sum() < 10:\n",
    "    # if dataset doesn't use 0-as-empty or not enough samples, fall back to all\n",
    "    mask = np.ones(len(Y_cls_val), dtype=bool)\n",
    "\n",
    "coord_bias = (pred_loc[mask] - Y_loc_val[mask]).mean(axis=0).astype(np.float32)\n",
    "np.save(f\"{MODEL_DIR}/coord_bias.npy\", coord_bias)\n",
    "\n",
    "print(\"Saved coord_bias →\", f\"{MODEL_DIR}/coord_bias.npy\")\n",
    "print(\"coord_bias:\", coord_bias)\n",
    "print(\"bias computed on samples:\", int(mask.sum()), \"/\", len(mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c35733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039/1039 - 1s - 1ms/step - coords_euclid_mean: 0.5424 - coords_loss: 0.1174 - loss: 0.1174 - presence_accuracy: 1.0000 - presence_loss: 2.3664e-09\n",
      "Validation Evaluation: [0.11738386750221252, 2.3664017412272642e-09, 0.11739612370729446, 0.5424419045448303, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 7 — Optional quick eval + cleanup\n",
    "# =========================================================\n",
    "val_eval = full_model.evaluate(\n",
    "    x=[Z_PRE_val, Z_PHYS_val],\n",
    "    y={\"presence\": Y_cls_val, \"coords\": Y_loc_val_n},\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"Validation Evaluation:\", val_eval)\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50db14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "#Restart the kernel to free memory\n",
    "import IPython\n",
    "app = IPython.get_ipython()\n",
    "app.kernel.do_shutdown(True)  # True = restart, False = shutdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
