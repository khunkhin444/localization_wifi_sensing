{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b97ed8",
   "metadata": {},
   "source": [
    "# Import & Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03f5d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8da6f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0880c",
   "metadata": {},
   "source": [
    "# Paths & global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f16912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THESE ===\n",
    "WINDOW_ROOT = \"/home/tonyliao/Location_new_aoa_PDF\"   # folder containing amp_window_XXXXX.npy\n",
    "ENC_SAVE_PATH = \"/home/tonyliao/Location_new_aoa_PDF/models/prec_encoder.h5\"\n",
    "CLS_SAVE_PATH = \"/home/tonyliao/Location_new_aoa_PDF/models/prec_classifier.h5\"\n",
    "\n",
    "# presence labels: 0 = empty, 1 = non-empty\n",
    "CLASS_NAMES = [\"Door_PreCNN\", \"Left_PreCNN\", \"Right_PreCNN\",\"Top_PreCNN\", \"Empty_PreCNN\",\"Middle_PreCNN\",\"Above_PreCNN\",\"RuJun_PreCNN\",\"ChenZhu_PreCNN\",\"Below_PreCNN\"]\n",
    "\n",
    "# training config\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40\n",
    "LR = 1e-3\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375ab1b",
   "metadata": {},
   "source": [
    "# PreCNN feature helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996ad28",
   "metadata": {},
   "source": [
    "## PreCNN Feature Construction\n",
    "\n",
    "The amplitude window is:\n",
    "\n",
    "$$\n",
    "H(t,s,a) \\in \\mathbb{R}^{T \\times S \\times A}\n",
    "$$\n",
    "\n",
    "Averaging across antennas:\n",
    "\n",
    "$$\n",
    "\\tilde{H}(t,s) = \\frac{1}{A} \\sum_{a=1}^{A} H(t,s,a)\n",
    "$$\n",
    "\n",
    "Transpose to channel-first:\n",
    "\n",
    "$$\n",
    "X_{\\text{amp}} = \\tilde{H}^{\\top} \\in \\mathbb{R}^{S \\times T}\n",
    "$$\n",
    "\n",
    "Global normalization:\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}}(c,t) = \\frac{X_{\\text{amp}}(c,t) - \\mu_c}{\\sigma_c + 10^{-6}}\n",
    "$$\n",
    "\n",
    "Final PreCNN input:\n",
    "\n",
    "$$\n",
    "X_{\\text{pre}}(t) = \n",
    "\\left[\n",
    "X_{\\text{norm}}(:,t),\\; \\text{mean}_c,\\; \\text{std}_c\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed6aaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_PRECNN_STATS = True  # Step-2 requirement: amp + temporal mean + temporal std\n",
    "\n",
    "def add_precnn_stats_channels(amp_ct):\n",
    "    \"\"\"\n",
    "    amp_ct: [C_base, T]\n",
    "    returns: [C_pre, T]\n",
    "    \"\"\"\n",
    "    C_base, T = amp_ct.shape\n",
    "\n",
    "    mu = amp_ct.mean(axis=1, keepdims=True)         # [C_base,1]\n",
    "    sd = amp_ct.std(axis=1, keepdims=True) + 1e-6   # [C_base,1]\n",
    "\n",
    "    mu_rep = np.repeat(mu, T, axis=1)\n",
    "    sd_rep = np.repeat(sd, T, axis=1)\n",
    "\n",
    "    return np.concatenate([amp_ct, mu_rep, sd_rep], axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246b52f",
   "metadata": {},
   "source": [
    "# Loader for MATLAB amp_window_*.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c45574c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_precnn_input(path, mu=None, sigma=None):\n",
    "    \"\"\"\n",
    "    path: amp_window_XXXXX.npy\n",
    "    raw shape in file: [T, S, A]\n",
    "\n",
    "    Output: X_pre [T, C_pre] ready for PreCNN.\n",
    "    \"\"\"\n",
    "    amp = np.load(path).astype(np.float32)   # [T, S, A]\n",
    "\n",
    "    # Step 1: average over antennas\n",
    "    avecsi_like = amp.mean(axis=2)           # [T, S]\n",
    "\n",
    "    # Step 2: convert to channels-first\n",
    "    amp_ct = avecsi_like.T                   # [S, T]\n",
    "    amp_ct = amp_ct - np.median(amp_ct, axis=1, keepdims=True)\n",
    "    # Eq(6),(8): reduce distance/wall scale sensitivity\n",
    "    q75 = np.percentile(amp_ct, 75, axis=1, keepdims=True)\n",
    "    q25 = np.percentile(amp_ct, 25, axis=1, keepdims=True)\n",
    "    amp_ct = amp_ct / (q75 - q25 + 1e-6)\n",
    "    # Step 3: normalize per-channel (computed later)\n",
    "    if mu is not None and sigma is not None:\n",
    "        amp_ct = (amp_ct - mu[:, None]) / (sigma[:, None] + 1e-6)\n",
    "\n",
    "    # Step 4: add PreCNN stat channels\n",
    "    if USE_PRECNN_STATS:\n",
    "        amp_ct = add_precnn_stats_channels(amp_ct)   # [C_pre, T]\n",
    "\n",
    "    # Step 5: final format for Keras\n",
    "    X_pre = np.transpose(amp_ct, (1, 0))             # [T, C_pre]\n",
    "    return X_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ce405",
   "metadata": {},
   "source": [
    "# File listing + label function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b776695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found windows: 404573\n"
     ]
    }
   ],
   "source": [
    "def list_amp_files(root):\n",
    "    return sorted(glob.glob(os.path.join(root, \"**\", \"amp_window_*.npy\"), recursive=True))\n",
    "\n",
    "def infer_label(path):\n",
    "    up = path.upper()\n",
    "    if \"EMPTY\" in up:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "amp_files = list_amp_files(WINDOW_ROOT)\n",
    "print(\"Found windows:\", len(amp_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba6bcc",
   "metadata": {},
   "source": [
    "# Compute global channel statistics (mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8ccfa",
   "metadata": {},
   "source": [
    "### Global Channel Statistics (μ, σ)\n",
    "\n",
    "For each subcarrier channel \\(c\\):\n",
    "\n",
    "Mean:\n",
    "\n",
    "$$\n",
    "\\mu_c \n",
    "= \\frac{1}{N} \\sum_{i=1}^{N}\n",
    "\\left(\n",
    "\\frac{1}{T} \\sum_{t=1}^{T} X_i(c,t)\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Second moment:\n",
    "\n",
    "$$\n",
    "m_{2,c} =\n",
    "\\frac{1}{N} \\sum_{i=1}^{N}\n",
    "\\left(\n",
    "\\frac{1}{T} \\sum_{t=1}^{T} X_i(c,t)^2\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Standard deviation:\n",
    "\n",
    "$$\n",
    "\\sigma_c = \\sqrt{m_{2,c} - \\mu_c^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de50e139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: (53,) sigma: (53,)\n"
     ]
    }
   ],
   "source": [
    "def compute_mu_sigma(paths, sample_limit=None):\n",
    "    sums = None\n",
    "    sq_sums = None\n",
    "    count = 0\n",
    "\n",
    "    for i, p in enumerate(paths):\n",
    "        if sample_limit and i >= sample_limit:\n",
    "            break\n",
    "\n",
    "        raw = np.load(p)        # [T, S, A]\n",
    "        avecsi_like = raw.mean(axis=2)   # [T, S]\n",
    "        amp_ct = avecsi_like.T           # [S, T]\n",
    "        amp_ct = amp_ct - np.median(amp_ct, axis=1, keepdims=True)\n",
    "        # Eq(6),(8): reduce distance/wall scale sensitivity\n",
    "        q75 = np.percentile(amp_ct, 75, axis=1, keepdims=True)\n",
    "        q25 = np.percentile(amp_ct, 25, axis=1, keepdims=True)\n",
    "        amp_ct = amp_ct / (q75 - q25 + 1e-6)    \n",
    "        C, _ = amp_ct.shape\n",
    "        if sums is None:\n",
    "            sums = np.zeros((C,), dtype=np.float64)\n",
    "            sq_sums = np.zeros((C,), dtype=np.float64)\n",
    "\n",
    "        sums    += amp_ct.mean(axis=1)\n",
    "        sq_sums += (amp_ct**2).mean(axis=1)\n",
    "        count += 1\n",
    "\n",
    "    mu = sums / count\n",
    "    sigma = np.sqrt(sq_sums / count - mu**2)\n",
    "    return mu.astype(np.float32), sigma.astype(np.float32)\n",
    "\n",
    "mu_global, sigma_global = compute_mu_sigma(amp_files)\n",
    "print(\"mu:\", mu_global.shape, \"sigma:\", sigma_global.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11de09",
   "metadata": {},
   "source": [
    "# Build dataset (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e974908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (404573, 4, 159) y shape: (404573,)\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for path in amp_files:\n",
    "    x = load_precnn_input(path, mu=mu_global, sigma=sigma_global)\n",
    "    X_list.append(x)\n",
    "    y_list.append(infer_label(path))\n",
    "\n",
    "X = np.stack(X_list, axis=0)    # [N, T, C_pre]\n",
    "y = np.array(y_list)\n",
    "\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbfb456",
   "metadata": {},
   "source": [
    "# Train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "164b3050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (323658, 4, 159) Val: (80915, 4, 159)\n"
     ]
    }
   ],
   "source": [
    "N = X.shape[0]\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "split = int(N * (1 - VAL_SPLIT))\n",
    "train_idx = idx[:split]\n",
    "val_idx   = idx[split:]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_val,   y_val   = X[val_idx],   y[val_idx]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ec30f",
   "metadata": {},
   "source": [
    "# Build PreCNN backbone + classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c2268",
   "metadata": {},
   "source": [
    "# PreCNN Backbone (Encoder)\n",
    "\n",
    "The encoder applies temporal convolutions:\n",
    "\n",
    "$$\n",
    "X^{(1)} = \\text{Conv1D}_{64, k=5}(X_{\\text{pre}})\n",
    "$$\n",
    "\n",
    "$$\n",
    "X^{(2)} = \\text{Conv1D}_{128, k=5}(\\text{Pool}(X^{(1)}))\n",
    "$$\n",
    "\n",
    "$$\n",
    "X^{(3)} = \\text{Conv1D}_{256, k=3}(\\text{Pool}(X^{(2)}))\n",
    "$$\n",
    "\n",
    "Global average pooling:\n",
    "\n",
    "$$\n",
    "f = \\text{GAP}(X^{(3)})\n",
    "$$\n",
    "\n",
    "Embedding vector:\n",
    "\n",
    "$$\n",
    "z = \\text{Dense}_{128}(f)\n",
    "$$\n",
    "\n",
    "\n",
    "### Softmax Classifier\n",
    "\n",
    "$$\n",
    "\\hat{y}_k = \n",
    "\\frac{e^{w_k^{\\top} z}}\n",
    "{\\sum_{j=1}^{K} e^{w_j^{\\top} z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "702d3c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768479752.642814  907074 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22181 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"PreCNN_Classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"PreCNN_Classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">159</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ precnn_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m159\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m50,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m41,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m98,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ precnn_embedding (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">226,570</span> (885.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m226,570\u001b[0m (885.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,674</span> (881.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,674\u001b[0m (881.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_precnn_backbone(T, C):\n",
    "    inp = layers.Input(shape=(T, C))\n",
    "\n",
    "    x = layers.Conv1D(64, 5, padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "\n",
    "    x = layers.Conv1D(128, 5, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    emb = layers.Dense(128, activation=\"relu\", name=\"precnn_embedding\")(x)\n",
    "    return models.Model(inp, emb, name=\"PreCNN_Encoder\")\n",
    "\n",
    "\n",
    "def build_classifier(encoder, num_classes):\n",
    "    inp = encoder.input\n",
    "    feat = encoder.output\n",
    "    x = layers.Dropout(0.3)(feat)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return models.Model(inp, out, name=\"PreCNN_Classifier\")\n",
    "\n",
    "\n",
    "T, C_pre = X_train.shape[1], X_train.shape[2]\n",
    "encoder = build_precnn_backbone(T, C_pre)\n",
    "clf = build_classifier(encoder, len(CLASS_NAMES))\n",
    "\n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82270e69",
   "metadata": {},
   "source": [
    "# Train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd4a4c",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "Training minimizes sparse categorical cross-entropy:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}\n",
    "=\n",
    "- \\log \\left( \\hat{y}_{\\,y_{\\text{true}}} \\right)\n",
    "$$\n",
    "\n",
    "Adam optimizer updates parameters:\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta - \\eta \\, \\frac{\\partial \\mathcal{L}}{\\partial \\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e562603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768479754.173182  907240 service.cc:152] XLA service 0x7fbf8c024a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1768479754.173196  907240 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2026-01-15 12:22:34.195297: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1768479754.319249  907240 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1768479755.881006  907240 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2026-01-15 12:22:46.714463: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2026-01-15 12:22:47.943840: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91103, saving model to /home/tonyliao/Location_new_aoa_PDF/models/prec_classifier.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5058/5058 - 15s - 3ms/step - accuracy: 0.9067 - loss: 0.3140 - val_accuracy: 0.9110 - val_loss: 0.2964\n",
      "Epoch 2/40\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.91103\n",
      "5058/5058 - 10s - 2ms/step - accuracy: 0.9089 - loss: 0.2939 - val_accuracy: 0.9105 - val_loss: 0.2888\n",
      "Epoch 3/40\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.91103\n",
      "5058/5058 - 12s - 2ms/step - accuracy: 0.9088 - loss: 0.2884 - val_accuracy: 0.9109 - val_loss: 0.2864\n",
      "Epoch 4/40\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.91103\n",
      "5058/5058 - 10s - 2ms/step - accuracy: 0.9088 - loss: 0.2854 - val_accuracy: 0.9110 - val_loss: 0.2895\n",
      "Epoch 5/40\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.91103\n",
      "5058/5058 - 10s - 2ms/step - accuracy: 0.9088 - loss: 0.2830 - val_accuracy: 0.9109 - val_loss: 0.2865\n",
      "Epoch 6/40\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.91103\n",
      "5058/5058 - 11s - 2ms/step - accuracy: 0.9087 - loss: 0.2814 - val_accuracy: 0.9107 - val_loss: 0.2867\n",
      "Epoch 7/40\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.91103\n",
      "5058/5058 - 12s - 2ms/step - accuracy: 0.9087 - loss: 0.2785 - val_accuracy: 0.9108 - val_loss: 0.2842\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Classifier saved: /home/tonyliao/Location_new_aoa_PDF/models/prec_classifier.h5\n"
     ]
    }
   ],
   "source": [
    "clf.compile(\n",
    "    optimizer=optimizers.Adam(LR),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "ckpt = callbacks.ModelCheckpoint(\n",
    "    CLS_SAVE_PATH, save_best_only=True, monitor=\"val_accuracy\", verbose=1\n",
    ")\n",
    "es = callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=6, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ckpt, es],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"Classifier saved:\", CLS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b522e82d",
   "metadata": {},
   "source": [
    "# Save encoder alone (for Step 3 & Step 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44bdbba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder saved: /home/tonyliao/Location_new_aoa_PDF/models/prec_encoder.h5\n"
     ]
    }
   ],
   "source": [
    "encoder.save(ENC_SAVE_PATH)\n",
    "print(\"Encoder saved:\", ENC_SAVE_PATH)\n",
    "#Release resources\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a9230",
   "metadata": {},
   "source": [
    "# Reset Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24261f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "#Restart the kernel to free memory\n",
    "import IPython\n",
    "app = IPython.get_ipython()\n",
    "app.kernel.do_shutdown(True)  # True = restart, False = shutdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
